% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tidy-methods.R
\name{augment.tidylda}
\alias{augment.tidylda}
\title{Augment method for \code{tidylda} bjects}
\usage{
\method{augment}{tidylda}(x, data, type = c("class", "prob"), ...)
}
\arguments{
\item{x}{an object of class \code{tidylda}}

\item{data}{a tidy tibble containing one row per original document-token pair, 
such as is returned by \link[tidytext]{tdm_tidiers} with column names
c("document", "term") at a minimum.}

\item{type}{one of either "class" or "prob"}

\item{...}{other arguments passed to methods,currently not used}
}
\value{
\code{augment} returns a tidy tibble containing one row per document-token
  pair, with one or more columns appended, depending on the value of \code{type}.
  
  If \code{type = 'prob'}, then one column per topic is appended. Its value
  is P(topic | document, token).
  
  If \code{type = 'class'}, then the most-probable topic for each document-token
  pair is returned. If multiple topics are equally probable, then the topic
  with the smallest index is returned by default.
}
\description{
\code{augment} appends observation level model outputs.
}
\details{
The key statistic for \code{augment} is P(topic | document, token) =
  P(topic | token) * P(token | document). P(topic | token) are the entries
  of the 'gamma' matrix in the \code{\link[tidylda]{tidylda}} object passed
  with \code{x}. P(token | document) is taken to be the frequency of each
  token normalized within each document.
}
\examples{
\donttest{
docs <- textmineR::nih_sample 

# tokenize using tidytext's unnest_tokens
tidy_docs <- docs \%>\% 
  select(APPLICATION_ID, ABSTRACT_TEXT) \%>\% 
  unnest_tokens(output = word, 
                input = ABSTRACT_TEXT,
                stopwords = stop_words$word,
                token = "ngrams",
                n_min = 1, n = 2) \%>\% 
  count(APPLICATION_ID, word) \%>\% 
  filter(n>1) #Filtering for words/bigrams per document, rather than per corpus

tidy_docs <- tidy_docs \%>\% # filter words that are just numbers
  filter(! stringr::str_detect(tidy_docs$word, "^[0-9]+$"))
  
dtm <- tidy_docs \%>\% 
  cast_sparse(APPLICATION_ID, word, n)

lda <- tidylda(dtm = dtm, k = 10, iterations = 100, burnin = 75)

# using sparse dtm
augment(lda, dtm, "prob")

# using tidy tibble
augment(lda, tidy_docs, "class")
}
}
